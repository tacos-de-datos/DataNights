{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataNights-VISceral\n",
    "#### C칩digo estructurado para las #DataNights de VISceral\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Meta</strong></summary>\n",
    "    La meta de este notebook es recrear el an치lisis de <a href=\"https://twitter.com/moaimx\">@moaimx</a> que hizo en <a href=\"https://twitter.com/search?q=%23datanights&src=typed_query\">#DataNights</a>\n",
    "    <ul>\n",
    "        <li> Limpiar las bases de datos del Secretariado sobre carpetas de investigaci칩n y v칤ctimas de homicidios dolosos. </li>\n",
    "        <ul>\n",
    "            <li> Extraer y transformar el conjunto de datos <strong>Estatal-Delitos-2015-2019_mar19.zip</strong> y <strong>Estatal-V칤ctimas-2015-2019_mar19.zip</strong></li>\n",
    "            <li> Guardar las bases de datos en formato .csv para facilitar el uso en un futuro. </li>\n",
    "            <li> Crear una base de datos lista para visualizaci칩n (en formato <i>tidy</i>). </li>\n",
    "        </ul>\n",
    "    </ul>\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "    <summary><strong>Contexto</strong></summary>\n",
    "    Adquirimos los datos en bruto del <a href=\"http://www.morlan.mx/blog/2019/04/21/datanights-y-el-regreso-de-este-blog/\">blog sobre #DataNights </a> en <a href=\"morlan.mx\">morlan.mx</a>\n",
    "    Tambi칠n seguiremos cercanamente los pasos para recrear lo que hicieron en los primeros dos episodios:\n",
    "    <ul>\n",
    "        <li><a href=\"https://www.youtube.com/watch?v=K2cYa41zmdw\"> Episodio 1 </a></li>\n",
    "        <li><a href=\"https://www.youtube.com/watch?v=xxQlCioKTe8\"> Episodio 2 </a></li>\n",
    "    </ul>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from zipfile import ZipFile\n",
    "from pathlib import Path\n",
    "from herramientas import arbol\n",
    "from datetime import datetime as dt\n",
    "hoy = dt.today().strftime(\"%d-%b-%y\")\n",
    "\n",
    "hoy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATOS_BRUTOS = Path(\"../datos/brutos/\")\n",
    "DATOS_INTERINOS = Path(\"../datos/interinos/\")\n",
    "DATOS_PROCESADOS = Path(\"../datos/procesados/\")\n",
    "DATOS_EXTERNOS = Path(\"../datos/externos/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol(DATOS_BRUTOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Extraer datos de un archivo .zip\n",
    "Para extraer datos de un archivo `.zip` utilizamos la biblioteca 游닄 de python `zipfile` de la siguiente manera:\n",
    "\n",
    "<details>\n",
    "    <summary>Nota</summary>\n",
    "    En la primera celda de c칩digo de este notebook importamos el objeto <code style=\"background-color:#eeeeee\">ZipFile</code> de la biblioteca <code style=\"background-color:#eee\">zipfile</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_zip_delitos = ZipFile(DATOS_BRUTOS / \"Estatal-Delitos-2015-2019_mar19.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Nota sobre <code style=\"background-color:#eee\">DATOS_BRUTOS / <span style=\"color:#ba2121\">\"Estatal-Delitos-2015-2019_mar19.zip\"</span></code></summary>\n",
    "    El objeto <code style=\"background-color:#eeeeee\">Path</code> de la biblioteca <code style=\"background-color:#eee\">pathlib</code> tiene la \"habilidad\" de conectar rutas de archivos utilizando el s칤mbolo \"/\". Independientemente del sistema operativo que utilices. <br>\n",
    "    Lo cual significa que si <code style=\"background-color:#eee\">DATOS_BRUTOS / <span style=\"color:#ba2121\">\"Estatal-Delitos-2015-2019_mar19.zip\"</span></code> es igual a <code style=\"background-color:#eee;color:#ba2121\">\"../datos/brutos/Estatal-Delitos-2015-2019_mar19.zip\"</code> <br>\n",
    "    o <code style=\"background-color:#eee;color:#ba2121\">\"..\\datos\\brutos\\Estatal-Delitos-2015-2019_mar19.zip\"</code> si estas en Windows (se formatea automaticamente).\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora `archivo_zip_delitos` es un objeto `ZipFile` as칤 que podemos hacer lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver la lista de archivos que tiene\n",
    "archivo_zip_delitos.filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "extraer los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_zip_delitos.extractall(path = DATOS_INTERINOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora en nuestro archivo `datos/interinos/` existe el archivo `'Estatal Delitos - marzo 2019.xlsb'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol(DATOS_INTERINOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos lo mismo con el archivo de v칤ctimas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_zip_victimas = ZipFile(DATOS_BRUTOS / 'Estatal-V칤ctimas-2015-2019_mar19.zip')\n",
    "archivo_zip_victimas.extractall(DATOS_INTERINOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol(DATOS_INTERINOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Leer archivos Excel en `Pandas`\n",
    "\n",
    "`Pandas` tiene la habilidad de leer archivos excel directamente pero un archivo excel esta compuesto de varias hojas as칤 que leemos estas hojas en dos pasos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "archivo_delitos = pd.ExcelFile(DATOS_INTERINOS / 'Estatal Delitos - marzo 2019.xlsb', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Archivos XLSB (Excel Binario) no tienen soporte en las bibliotecas modernas de python pero existe una biblioteca no muy conocida llamada `pyxlsb` que nos puede ayudar. <br>\n",
    "La puedes instalar con `pip` desde tu terminal:\n",
    "```shell\n",
    "pip install pyxlsb\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyxlsb\n",
    "# vamos a excribir csv a la anti칲ita\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyxlsb.open_workbook(DATOS_INTERINOS / 'Estatal Delitos - marzo 2019.xlsb') as workbook:\n",
    "    for nombre in workbook.sheets:\n",
    "        with workbook.get_sheet(nombre) as hoja, open(DATOS_INTERINOS / f\"delitos-{nombre}.csv\", 'w',  encoding = 'utf-8') as f:\n",
    "            escritor_csv = csv.writer(f)\n",
    "            for fila in hoja.rows():\n",
    "                escritor_csv.writerow([celda.v for celda in fila])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol(DATOS_INTERINOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que estamos haciendo es:\n",
    "1. Abrir el archivo y asignandolo a la variable \"workbook\"\n",
    "2. Creamos una \"loop\" (o bucle) para hacer X ejercicio en cada hoja del workbook (`workbook.sheets`)\n",
    "3. Creamos un archivo \"delitos-{nombre de la hoja}.csv\" \n",
    "4. Creamos un \"escritor\" de csv \n",
    "5. Hacemos otra \"loop\" (o bucle) y por cada fila en nuestra hoja creamos una lista con los valores de cada celda en esa fila la cual escribimos a nuestro archivo .csv <- esta es la parte m치s d칤ficil de comprender porque son 3 pasos en uno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hagamos lo mismo con el archivo de v칤ctimas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pyxlsb.open_workbook(DATOS_INTERINOS / 'Estatal V칤ctimas - marzo 2019.xlsb') as workbook:\n",
    "    for nombre in workbook.sheets:\n",
    "        with workbook.get_sheet(nombre) as hoja, open(DATOS_INTERINOS / f\"victimas-{nombre}.csv\", 'w', encoding = 'utf-8') as f:\n",
    "            escritor_csv = csv.writer(f)\n",
    "            for fila in hoja.rows():\n",
    "                escritor_csv.writerow([celda.v for celda in fila])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol(DATOS_INTERINOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta \"loop\" crea un archivo `.csv` por cada hoja en el archivo `.xlsb` as칤 que este pedacito de c칩digo funciona aunque tu archivo excel tenga 150 hojas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Creando un conjunto de datos listos para visualizaci칩n (en formato `tidy`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta el momento llevamos 2 de nuestras 3 metas:<br>\n",
    "<input type=\"checkbox\" checked> Extraer y transformar el conjunto de datos <strong>Estatal-Delitos-2015-2019_mar19.zip</strong> y <strong>Estatal-V칤ctimas-2015-2019_mar19.zip</strong><br>\n",
    "<input type=\"checkbox\" checked> Guardar las bases de datos en formato .csv para facilitar el uso en un futuro.<br>\n",
    "<input type=\"checkbox\" > Crear una base de datos lista para visualizaci칩n (en formato <i>tidy</i>)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El limpiar y restructurar datos siempre es lo que lleva m치s tiempo en el proceso de an치lisis de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos = pd.read_csv(DATOS_INTERINOS / 'delitos-Hoja1.csv')\n",
    "victimas = pd.read_csv(DATOS_INTERINOS / 'victimas-Hoja1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTA:\n",
    "Este tutorial **asume** que viste los episodios 1 y 2 de #DataNights. No vamos a explicar porque estamos escogiendo las variables que estamos escogiendo o lo que ilustran cada uno de estos conjuntos de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El producto final de ambos conjuntos (v칤ctimas y delitos) es parecido: un conjunto de datos con las columnas \"A침o\", \"Mes\", \"Delitos\" o \"V칤ctimas\" donde esta la cuenta total (agregada) de los delitos o v칤ctimas en M칠xico en ese A침o-Mes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando datos\n",
    "Primero vemos los valores _unicos_ en nuestra columna 'Supbipo de delito' para asegurarnos de que no haya errores de dedo. Por ejemplo, en bases de datos de baja calidad puedes encontrar:\n",
    "1. \"Homicidio doloso\"\n",
    "2. \"Homicidio doloso \"\n",
    "3. \" Homicidio doloso\"\n",
    "4. \"homicidio doloso\"\n",
    "5. \"Homicidio Doloso\"\n",
    "\n",
    "Todos estos valores son distintos para `pandas`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos['Subtipo de delito'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que vemos que nuestra columna 'Subtipo de delito' si est치 bien construida/limpia podemos crear \"m치scaras\" para filtrar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_homicidio_doloso_delitos = delitos['Subtipo de delito'] == 'Homicidio doloso'\n",
    "mascara_homicidio_doloso_victimas = victimas['Subtipo de delito'] == 'Homicidio doloso'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para m치s informaci칩n sobre como funciona esto ve los videos de DataNights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos[mascara_homicidio_doloso_delitos].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas[mascara_homicidio_doloso_victimas].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota el _brinco_ en el 칤ndice en ambos **DataFrames**. Esto significa que hemos eliminado todas las filas que no cumplan el requisito de la \"m치scara\" (que la columna \"Subtipo de delito\" equivalga \"Homicidio doloso\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos = delitos[mascara_homicidio_doloso_delitos].copy()\n",
    "victimas = victimas[mascara_homicidio_doloso_victimas].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Nota sobre <code style=\"background-color:#eee\">.<span style=\"color:#0055AA\">copy</span>()</code></summary>\n",
    "    Utilizar <code style=\"background-color:#eee\">.<span style=\"color:#0055AA\">copy</span>()</code> no es necesario ya que estamos sobreescribiendo la variable delitos. <code style=\"background-color:#eee\">.<span style=\"color:#0055AA\">copy</span>()</code> es necesario cuando estas creando una copia de una parte de otro DataFrame. Pandas por defecto va a crear una especie de \"vista\" en lugar de una copia copia. Esto puede tener consecuencias no deseadas m치s adelante en tus an치lisis. As칤 que es buena practica utilizar <code style=\"background-color:#eee\">.<span style=\"color:#0055AA\">copy</span>()</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trabajando con fechas\n",
    "`python` es muy bueno trabajando con fechas. En la biblioteca est치ndard (que viene incluida en `python`) existe el paquete `datetime` para trabajar con fechas y tiempos. Es posible utilizar este paquete para trabajar con fechas en espa침ol tambi칠n (s칩lo es cuesti칩n de cambiar el `LC_TIME`) pero existen otros paquetes como `arrow` que hacen el proceso de trabajar con fechas mucho m치s amigable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrow.locales.SpanishLocale.month_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Arrow` tiene \"locales\" para muchos muchos idiomas. En este caso vamos a utilizar el `SpanishLocale` para obtener una lista de los meses m치s rapidamente que escribiendolos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta es una list comprehension - ve el video de DataNights para aprender m치s sobre esto\n",
    "meses = [mes.title() for mes in arrow.locales.SpanishLocale.month_names if mes]\n",
    "meses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: agregamos el `if mes` para decirle a `python` que me de un `mes` con la primera letra en may칰scula (`.title()`) **s칩lo** si `mes` existe/es `True`. En `python` las cadenas ( o _strings_) tienen un valor equivalente a `False` si est치n vac칤as (como el primer valor de la lista `arrow.locales.SpanishLocale.month_names`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos crear una lista de \"columnas de inter칠s\", las columnas que vamos a utilizar en nuestro an치lisis. Aqu칤 es de donde partimos un poco del proceso utilizado en DataNights. \n",
    "\n",
    "Hacemos esto por preferencia personal. Antes de restructurar conjuntos de datos, a m칤, en lo personal, me gusta filtrar todo lo que no voy a utilizar. Esto significa, eliminar filas **y** columnas que no crea necesarias para mi an치lisis. \n",
    "\n",
    "Primero creamos una lista de columnas que nos interesan. En este caso van a ser el A침o y los meses. Como ya tenemos una lista de meses lo que hacemos es `extend`er una primera lista (que solo tiene \"A침o\") para incluir los meses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_de_interes = ['A침o']\n",
    "columnas_de_interes.extend(meses)\n",
    "columnas_de_interes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto funciona igual que las m치scaras que utilizamos anteriormente para filtrar filas. Y ya que ambos **DataFrame**s tienen las mismas columnas, no ocupamos crear dos \"m치scaras\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos[columnas_de_interes].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas[columnas_de_interes].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos = delitos[columnas_de_interes].copy()\n",
    "victimas = victimas[columnas_de_interes].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derretir nuestos datasets\n",
    "Reitero: No vamos a explicar todo esto en este tutorial. Si no sabes lo que estamos haciendo aqu칤, ve a ver los episodios 1 y 2 de #DataNights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos_derretido = delitos.melt(id_vars = 'A침o', var_name = 'Mes', value_name = 'Cuenta (carpetas)')\n",
    "victimas_derretido = victimas.melt(id_vars = 'A침o', var_name = 'Mes', value_name = 'Cuenta (victimas)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos nuestros nuevos **DataFrame**s en esta nueva estructura (derretida) es cuando yo modificar칤a los valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necesitamos un _diccionario_ con los nombres del mes como llave y sus valores correspondientes (01-12). \n",
    "\n",
    "Igual que hicimos una \"list comprehension\" podemos hacer un \"dict comprehension\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{mes: valor for valor, mes in enumerate(meses, start = 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero queremos los valores en formato \"01\" en lugar de 1. Para eso utilizamos `.zfill()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{mes: str(valor).zfill(2) for valor, mes in enumerate(meses, start = 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sustituciones_meses = {mes: str(valor).zfill(2) for valor, mes in enumerate(meses, start = 1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora podemos sustituir nuestra columna de \"Mes\" por valores n칰mericos (m치s o menos n칰mericos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido[\"Mes\"] = victimas_derretido[\"Mes\"].map(sustituciones_meses)\n",
    "delitos_derretido[\"Mes\"] = delitos_derretido[\"Mes\"].map(sustituciones_meses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora transformamos nuestra columna \"A침o\" a _string_ para concatenarla con \"Mes\" para tener una columna \"A침o-Mes\" que utilizaremos como nuestro eje X.\n",
    "\n",
    "Primero la convertimos a `int` o enteros para deshacernos del .0 al final de cada n칰mero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido['A침o'] = victimas_derretido['A침o'].astype(int).astype(str)\n",
    "delitos_derretido['A침o'] = delitos_derretido['A침o'].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido['Fecha'] = victimas_derretido[\"A침o\"] + '-' + victimas_derretido['Mes']\n",
    "delitos_derretido['Fecha'] = delitos_derretido[\"A침o\"] + '-' + delitos_derretido['Mes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos estos valores \"Fecha\" podemos agrupar nuestros datos por esta columna y agregarlos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido.groupby(\"Fecha\")['Cuenta (victimas)'].sum().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_derretido.groupby(\"Fecha\")[['Cuenta (victimas)']].sum().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota que si utilizas [[\"___________\"]] en lugar de un solo par de corchetes recibir치s un **DataFrame** en lugar de una **Serie** de pandas por defecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_agrupado = victimas_derretido.groupby(\"Fecha\")[['Cuenta (victimas)']].sum().reset_index()\n",
    "delitos_agrupado = delitos_derretido.groupby(\"Fecha\")[['Cuenta (carpetas)']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_agrupado.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero como vimos en #DataNights, nuestro conjunto de datos tiene columnas para todos los meses del a침o pero valores solo hasta marzo 2019. Esto significa que empezando en abril, los valores son en nuestro conjunto modificado son 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_agrupado.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como nuestros datos estan ordenados podemos hacer algo como"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "victimas_agrupado[:-9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eliminando las ultimas 9 filas del **DataFrame**. Tambi칠n sabemos ning칰n par de A침o-Mes tiene un valor equivalente a 0 de manera natural as칤 que podemos crear una m치scara para filtrar las filas que no cumplan este requisito. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mascara_cuenta_victimas = victimas_agrupado['Cuenta (victimas)'] > 0\n",
    "mascara_cuenta_delitos = delitos_agrupado['Cuenta (carpetas)'] > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos_agrupado[mascara_cuenta_delitos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos_agrupado = delitos_agrupado[mascara_cuenta_delitos].copy()\n",
    "victimas_agrupado = victimas_agrupado[mascara_cuenta_victimas].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 춰Listo!\n",
    "Tenemos nuestros conjuntos de datos listos para visualizar. \n",
    "Guardemoslos en formato `.csv` para facilitar su uso en un futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delitos_agrupado.to_csv(DATOS_PROCESADOS / f'carpetas-cuenta-{hoy}.csv', encoding = 'utf-8', index = False)\n",
    "victimas_agrupado.to_csv(DATOS_PROCESADOS / f'victimas-cuenta-{hoy}.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Visualizaci칩n\n",
    "Para mantener nuestro entorno de trabajo organizado crearemos nuestra visualizaci칩n en otro notebook. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
